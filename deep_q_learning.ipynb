{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, logging\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"tensorflow_hub\").setLevel(logging.CRITICAL)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import environment\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = environment\n",
    "\n",
    "n_episodes = 1000\n",
    "n_win_ticks = 1000\n",
    "\n",
    "gamma = 1.\n",
    "epsilon = 1.\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.999\n",
    "alpha = 0.001  \n",
    "alpha_decay = 0.001\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "memory = deque(maxlen = 1000)\n",
    "scores = deque(maxlen = 100)\n",
    "\n",
    "SHOW_EVERY = 1\n",
    "PLOT_EVERY = 100\n",
    "show =  True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim = 11, activation = 'relu'))\n",
    "model.add(Dense(48, activation = 'relu'))\n",
    "model.add(Dense(48, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'relu'))\n",
    "model.compile(loss = 'mse', optimizer = Adam(lr = alpha, decay = alpha_decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(state, action, reward, next_state, done):\n",
    "    memory.append((state, action, reward, next_state, done))   \n",
    "    \n",
    "def choose_action(state, epsilon):\n",
    "    if np.random.random() <= epsilon:\n",
    "        return env.sample() \n",
    "    else: \n",
    "        return np.argmax(model.predict(state))\n",
    "\n",
    "def get_epsilon(t):\n",
    "    return max(epsilon_min, min(epsilon, 1.0 - math.log10((t+1)*epsilon_decay)))\n",
    "\n",
    "def replay(batch_size, epsilon):\n",
    "    \n",
    "    x_batch, y_batch = [], []\n",
    "    minibatch = random.sample(memory, min(len(memory), batch_size))\n",
    "    \n",
    "    for state, action, reward, next_state, done in minibatch:  \n",
    "        \n",
    "        y_target = model.predict(state)\n",
    "        y_target[0][action] = -100 if done else reward + gamma*np.max(model.predict(next_state)[0])\n",
    "        for act in range(3):\n",
    "            if y_target[0][act] < 10:\n",
    "                y_target[0][act] = 10\n",
    "        x_batch.append(state[0])\n",
    "        y_batch.append(y_target[0])\n",
    "    \n",
    "    model.fit(np.array(x_batch), np.array(y_batch), batch_size = len(x_batch), verbose = 0)\n",
    "    \n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model1.h5')\n",
    "epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    ep = []\n",
    "    ticks = []\n",
    "    mean_score = []\n",
    "    # make the environment\n",
    "    env = environment\n",
    "    env.reset()\n",
    "    env.show = show\n",
    "    # run the loop for n_episodes\n",
    "    for e in range(n_episodes):\n",
    "        # Reset the environment\n",
    "        env.reset()\n",
    "        done = False\n",
    "        # First state\n",
    "        state = env.get_state()\n",
    "        # Reset the score counter\n",
    "        i = 0\n",
    "        # Run the loop - algorithm\n",
    "        while not done:\n",
    "            # get the action according the state.\n",
    "            action = choose_action(state, epsilon)\n",
    "            # Make the move\n",
    "            env.step(action)\n",
    "            # Get the next state from environment\n",
    "            next_state = env.get_state()\n",
    "            # Get the reward\n",
    "            reward = env.get_reward()\n",
    "            # Check if the programm has done\n",
    "            done = env.done\n",
    "            # Save the current situation\n",
    "            save(state, action, reward, next_state, done)\n",
    "            # Update the state\n",
    "            state = next_state\n",
    "            # Raise up the score\n",
    "            i += 1\n",
    "        \n",
    "        print(\"Episode {} run for {} ticks\".format(e, i))\n",
    "        replay(batch_size, get_epsilon(e))\n",
    "        \n",
    "        ep.append(e)\n",
    "        ticks.append(i)\n",
    "        scores.append(i)\n",
    "        mean_score.append(np.mean(scores))\n",
    "        \n",
    "        plt.plot(ep, ticks, 'b')\n",
    "        plt.plot(ep, mean_score, 'r')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Ticks')\n",
    "        if e % PLOT_EVERY == 0 and e > 1:\n",
    "            plt.show()\n",
    "        \n",
    "        if show == True:\n",
    "            if e % SHOW_EVERY == 0:\n",
    "                env.show = True\n",
    "            else:\n",
    "                env.show = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 run for 92 ticks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ScopedTFGraph.__del__ at 0x0000020DA8135168>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\EGiannakidis\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\framework\\c_api_util.py\", line 52, in __del__\n",
      "    c_api.TF_DeleteGraph(self.graph)\n",
      "AttributeError: 'ScopedTFGraph' object has no attribute 'graph'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 run for 120 ticks\n",
      "Episode 2 run for 67 ticks\n",
      "Episode 3 run for 55 ticks\n",
      "Episode 4 run for 59 ticks\n",
      "Episode 5 run for 78 ticks\n",
      "Episode 6 run for 85 ticks\n",
      "Episode 7 run for 98 ticks\n",
      "Episode 8 run for 68 ticks\n",
      "Episode 9 run for 50 ticks\n",
      "Episode 10 run for 75 ticks\n",
      "Episode 11 run for 87 ticks\n",
      "Episode 12 run for 54 ticks\n",
      "Episode 13 run for 87 ticks\n",
      "Episode 14 run for 64 ticks\n",
      "Episode 15 run for 84 ticks\n",
      "Episode 16 run for 78 ticks\n",
      "Episode 17 run for 60 ticks\n",
      "Episode 18 run for 81 ticks\n",
      "Episode 19 run for 95 ticks\n",
      "Episode 20 run for 95 ticks\n",
      "Episode 21 run for 104 ticks\n",
      "Episode 22 run for 104 ticks\n",
      "Episode 23 run for 62 ticks\n",
      "Episode 24 run for 79 ticks\n",
      "Episode 25 run for 59 ticks\n",
      "Episode 26 run for 48 ticks\n",
      "Episode 27 run for 63 ticks\n",
      "Episode 28 run for 59 ticks\n",
      "Episode 29 run for 51 ticks\n",
      "Episode 30 run for 83 ticks\n",
      "Episode 31 run for 88 ticks\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tensorflow.keras.models.load_model('model1.h5')\n",
    "def test(model):\n",
    "    i = 0\n",
    "    for _ in range(10):\n",
    "        i = 0\n",
    "        env = environment\n",
    "        env.show = True\n",
    "        env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            state = env.get_state()\n",
    "            action = np.argmax(model.predict(state))\n",
    "            env.step(action)\n",
    "            done = env.done\n",
    "            i += 1\n",
    "        print(\"The total ticks was {}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total ticks was 91\n",
      "The total ticks was 100\n",
      "The total ticks was 100\n",
      "The total ticks was 90\n",
      "The total ticks was 90\n",
      "The total ticks was 91\n",
      "The total ticks was 100\n",
      "The total ticks was 100\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a12fbaf8d0b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-83d96c8287a0>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Tensorflow\\Deep Q-learning\\following\\environment.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(action)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mwin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGREEN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0mmLimits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mmEnemy1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "test(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
