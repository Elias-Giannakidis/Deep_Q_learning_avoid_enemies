{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, logging\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"tensorflow_hub\").setLevel(logging.CRITICAL)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.7.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import environment\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = environment\n",
    "\n",
    "n_episodes = 1000\n",
    "n_win_ticks = 3000\n",
    "\n",
    "gamma = 0.999\n",
    "epsilon = 1.0\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "alpha = 0.01  \n",
    "alpha_decay = 0.01\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "memory = deque(maxlen = 10000)\n",
    "\n",
    "SHOW_EVERY = 20\n",
    "PLOT_EVERY = 20\n",
    "RESET_EVERY = 20\n",
    "show =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim = 11, activation = 'relu'))\n",
    "model.add(Dense(48, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "model.compile(loss = 'mse', optimizer = Adam(lr = alpha, decay = alpha_decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(state, action, reward, next_state, done):\n",
    "    memory.append((state, action, reward, next_state, done))   \n",
    "    \n",
    "def choose_action(state, epsilon):\n",
    "    if np.random.random() <= epsilon:\n",
    "        return env.sample() \n",
    "    else: \n",
    "        return np.argmax(model.predict(state))\n",
    "\n",
    "def get_epsilon(t):\n",
    "    return max(epsilon_min, min(epsilon, 1.0 - math.log10((t+1)*epsilon_decay)))\n",
    "\n",
    "def replay(batch_size, epsilon):\n",
    "    \n",
    "    x_batch, y_batch = [], []\n",
    "    minibatch = random.sample(memory, min(len(memory), batch_size))\n",
    "    \n",
    "    for state, action, reward, next_state, done in minibatch:  \n",
    "        \n",
    "        y_target = model.predict(state)\n",
    "        y_target[0][action] = reward if done else reward + gamma*np.max(model.predict(next_state)[0])\n",
    "        x_batch.append(state[0])\n",
    "        y_batch.append(y_target[0])\n",
    "    \n",
    "    model.fit(np.array(x_batch), np.array(y_batch), batch_size = len(x_batch), verbose = 0)\n",
    "    \n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    ep = []\n",
    "    ticks = []\n",
    "    # make the environment\n",
    "    env = environment\n",
    "    env.reset()\n",
    "    env.show = show\n",
    "    # run the loop for n_episodes\n",
    "    for e in range(n_episodes):\n",
    "        global memory\n",
    "        # Reset memory\n",
    "        if e % RESET_EVERY == 0:\n",
    "            memory = []\n",
    "        # Reset the environment\n",
    "        env.reset()\n",
    "        done = False\n",
    "        # First state\n",
    "        state = env.get_state()\n",
    "        # Reset the score counter\n",
    "        i = 0\n",
    "        # Run the loop - algorithm\n",
    "        while not done:\n",
    "            # get the action according the state.\n",
    "            action = choose_action(state, epsilon)\n",
    "            # Make the move\n",
    "            env.step(action)\n",
    "            # Get the next state from environment\n",
    "            next_state = env.get_state()\n",
    "            # Get the reward\n",
    "            reward = env.get_reward()\n",
    "            # Check if the programm has done\n",
    "            done = env.done\n",
    "            # Save the current situation\n",
    "            save(state, action, reward, next_state, done)\n",
    "            # Update the state\n",
    "            state = next_state\n",
    "            # Raise up the score\n",
    "            i += 1\n",
    "        \n",
    "        print(\"Episode {} run for {} ticks\".format(e, i))\n",
    "        replay(batch_size, get_epsilon(e))\n",
    "        \n",
    "        ep.append(e)\n",
    "        ticks.append(i)\n",
    "        \n",
    "        plt.plot(ep, ticks)\n",
    "        if e % PLOT_EVERY == 0 and e > 1:\n",
    "            plt.show()\n",
    "        \n",
    "        if show == True:\n",
    "            if e % SHOW_EVERY == 0:\n",
    "                env.show = True\n",
    "            else:\n",
    "                env.show = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 run for 37 ticks\n",
      "Episode 1 run for 31 ticks\n",
      "Episode 2 run for 23 ticks\n",
      "Episode 3 run for 24 ticks\n",
      "Episode 4 run for 46 ticks\n",
      "Episode 5 run for 27 ticks\n",
      "Episode 6 run for 28 ticks\n",
      "Episode 7 run for 40 ticks\n",
      "Episode 8 run for 49 ticks\n",
      "Episode 9 run for 34 ticks\n",
      "Episode 10 run for 27 ticks\n",
      "Episode 11 run for 32 ticks\n",
      "Episode 12 run for 22 ticks\n",
      "Episode 13 run for 28 ticks\n",
      "Episode 14 run for 23 ticks\n",
      "Episode 15 run for 28 ticks\n",
      "Episode 16 run for 24 ticks\n",
      "Episode 17 run for 45 ticks\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1.h5')\n",
    "new_model = tf.keras.models.load_model('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tensorflow.keras.models.load_model('model1.h5')\n",
    "def test(model):\n",
    "    i = 0\n",
    "    env = environment\n",
    "    env.show = True\n",
    "    env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        state = env.get_state()\n",
    "        action = np.argmax(model.predict(state))\n",
    "        env.step(action)\n",
    "        done = env.done\n",
    "        i += 1\n",
    "    print(\"The total ticks was {}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
